"""Add run queue management tables

Revision ID: e21397e52471
Revises: 8fdd48058112
Create Date: 2025-09-23 11:50:13.167999

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'e21397e52471'
down_revision: Union[str, Sequence[str], None] = '8fdd48058112'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_queued_runs_queue_position'), table_name='queued_runs')
    op.drop_index(op.f('ix_queued_runs_scope_hash'), table_name='queued_runs')
    op.drop_index(op.f('ix_queued_runs_status'), table_name='queued_runs')
    op.drop_table('queued_runs')
    op.add_column('analysis_presets', sa.Column('filters', sa.JSON(), nullable=True))
    op.add_column('analysis_presets', sa.Column('model_tag', sqlmodel.sql.sqltypes.AutoString(), nullable=False))
    op.add_column('analysis_presets', sa.Column('rate_per_second', sa.Float(), nullable=False))
    op.add_column('analysis_presets', sa.Column('is_default', sa.Boolean(), nullable=False))
    op.alter_column('analysis_presets', 'id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('analysis_presets', 'name',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False)
    op.alter_column('analysis_presets', 'description',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
    op.alter_column('analysis_presets', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('analysis_presets', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_column('analysis_presets', 'scope_json')
    op.drop_column('analysis_presets', 'params_json')
    op.add_column('analysis_run_items', sa.Column('processing_started_at', sa.DateTime(), nullable=True))
    op.add_column('analysis_run_items', sa.Column('processing_completed_at', sa.DateTime(), nullable=True))
    op.add_column('analysis_run_items', sa.Column('retry_count', sa.Integer(), nullable=False))
    op.alter_column('analysis_run_items', 'id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('analysis_run_items', 'run_id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.alter_column('analysis_run_items', 'item_id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.alter_column('analysis_run_items', 'state',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False,
               existing_server_default=sa.text("'queued'::text"))
    op.alter_column('analysis_run_items', 'error_message',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=True)
    op.drop_constraint(op.f('analysis_run_items_run_id_item_id_key'), 'analysis_run_items', type_='unique')
    op.drop_index(op.f('idx_run_items_item_id'), table_name='analysis_run_items')
    op.drop_index(op.f('idx_run_items_run_id'), table_name='analysis_run_items')
    op.drop_index(op.f('idx_run_items_state'), table_name='analysis_run_items')
    op.create_index(op.f('ix_analysis_run_items_item_id'), 'analysis_run_items', ['item_id'], unique=False)
    op.create_index(op.f('ix_analysis_run_items_run_id'), 'analysis_run_items', ['run_id'], unique=False)
    op.create_index(op.f('ix_analysis_run_items_state'), 'analysis_run_items', ['state'], unique=False)
    op.drop_constraint(op.f('analysis_run_items_run_id_fkey'), 'analysis_run_items', type_='foreignkey')
    op.drop_constraint(op.f('analysis_run_items_item_id_fkey'), 'analysis_run_items', type_='foreignkey')
    op.create_foreign_key(None, 'analysis_run_items', 'items', ['item_id'], ['id'])
    op.create_foreign_key(None, 'analysis_run_items', 'analysis_runs', ['run_id'], ['id'])
    op.drop_column('analysis_run_items', 'cost_usd')
    op.drop_column('analysis_run_items', 'started_at')
    op.drop_column('analysis_run_items', 'tokens_used')
    op.drop_column('analysis_run_items', 'completed_at')
    op.drop_column('analysis_run_items', 'created_at')
    op.add_column('analysis_runs', sa.Column('filters', sa.JSON(), nullable=True))
    op.add_column('analysis_runs', sa.Column('total_items', sa.Integer(), nullable=True))
    op.add_column('analysis_runs', sa.Column('processed_items', sa.Integer(), nullable=True))
    op.add_column('analysis_runs', sa.Column('failed_items', sa.Integer(), nullable=True))
    op.add_column('analysis_runs', sa.Column('error_message', sqlmodel.sql.sqltypes.AutoString(), nullable=True))
    op.add_column('analysis_runs', sa.Column('avg_processing_time', sa.Float(), nullable=True))
    op.add_column('analysis_runs', sa.Column('model_tag', sqlmodel.sql.sqltypes.AutoString(), nullable=True))
    op.alter_column('analysis_runs', 'id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False,
               autoincrement=True,
               existing_server_default=sa.text("nextval('analysis_runs_id_seq'::regclass)"))
    op.alter_column('analysis_runs', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('analysis_runs', 'started_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.alter_column('analysis_runs', 'completed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.alter_column('analysis_runs', 'status',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::text"))
    op.alter_column('analysis_runs', 'scope_hash',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               nullable=True)
    op.drop_index(op.f('idx_analysis_runs_created'), table_name='analysis_runs')
    op.drop_index(op.f('idx_analysis_runs_scope_hash'), table_name='analysis_runs')
    op.drop_index(op.f('idx_analysis_runs_status'), table_name='analysis_runs')
    op.create_index(op.f('ix_analysis_runs_created_at'), 'analysis_runs', ['created_at'], unique=False)
    op.create_index(op.f('ix_analysis_runs_scope_hash'), 'analysis_runs', ['scope_hash'], unique=False)
    op.create_index(op.f('ix_analysis_runs_status'), 'analysis_runs', ['status'], unique=False)
    op.drop_column('analysis_runs', 'cost_estimate')
    op.drop_column('analysis_runs', 'queued_count')
    op.drop_column('analysis_runs', 'error_rate')
    op.drop_column('analysis_runs', 'scope_json')
    op.drop_column('analysis_runs', 'processed_count')
    op.drop_column('analysis_runs', 'actual_cost')
    op.drop_column('analysis_runs', 'coverage_60m')
    op.drop_column('analysis_runs', 'last_error')
    op.drop_column('analysis_runs', 'failed_count')
    op.drop_column('analysis_runs', 'params_json')
    op.drop_column('analysis_runs', 'updated_at')
    op.drop_column('analysis_runs', 'items_per_min')
    op.drop_column('analysis_runs', 'coverage_10m')
    op.drop_column('analysis_runs', 'eta_seconds')
    op.alter_column('dynamic_feed_templates', 'usage_count',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('feed_health', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.add_column('feed_types', sa.Column('updated_at', sa.DateTime(), nullable=False))
    op.add_column('item_analysis', sa.Column('id', sa.Integer(), nullable=False))
    op.add_column('item_analysis', sa.Column('sentiment_score', sa.Float(), nullable=True))
    op.add_column('item_analysis', sa.Column('sentiment_label', sqlmodel.sql.sqltypes.AutoString(), nullable=True))
    op.add_column('item_analysis', sa.Column('impact_score', sa.Float(), nullable=True))
    op.add_column('item_analysis', sa.Column('urgency_score', sa.Integer(), nullable=True))
    op.add_column('item_analysis', sa.Column('relevance_score', sa.Float(), nullable=True))
    op.add_column('item_analysis', sa.Column('impact_overall', sa.Integer(), nullable=True))
    op.add_column('item_analysis', sa.Column('raw_analysis_data', sa.JSON(), nullable=True))
    op.add_column('item_analysis', sa.Column('created_at', sa.DateTime(), nullable=False))
    op.alter_column('item_analysis', 'item_id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False)
    op.alter_column('item_analysis', 'model_tag',
               existing_type=sa.TEXT(),
               type_=sqlmodel.sql.sqltypes.AutoString(),
               comment=None,
               existing_comment='LLM model identifier used for analysis',
               existing_nullable=True)
    op.alter_column('item_analysis', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_index(op.f('idx_item_analysis_impact_overall'), table_name='item_analysis')
    op.drop_index(op.f('idx_item_analysis_sentiment_label'), table_name='item_analysis')
    op.drop_index(op.f('idx_item_analysis_updated'), table_name='item_analysis')
    op.drop_index(op.f('idx_item_analysis_urgency'), table_name='item_analysis')
    op.drop_index(op.f('item_analysis_item_id_idx'), table_name='item_analysis')
    op.create_index(op.f('ix_item_analysis_impact_overall'), 'item_analysis', ['impact_overall'], unique=False)
    op.create_index(op.f('ix_item_analysis_sentiment_label'), 'item_analysis', ['sentiment_label'], unique=False)
    op.create_index(op.f('ix_item_analysis_updated_at'), 'item_analysis', ['updated_at'], unique=False)
    op.create_index(op.f('ix_item_analysis_urgency_score'), 'item_analysis', ['urgency_score'], unique=False)
    op.create_unique_constraint(None, 'item_analysis', ['item_id'])
    op.drop_constraint(op.f('item_analysis_item_id_fkey'), 'item_analysis', type_='foreignkey')
    op.create_foreign_key(None, 'item_analysis', 'items', ['item_id'], ['id'])
    op.drop_table_comment(
        'item_analysis',
        existing_comment='Stores LLM-generated sentiment and impact analysis for news items',
        schema=None
    )
    op.drop_column('item_analysis', 'sentiment_json')
    op.drop_column('item_analysis', 'impact_json')
    op.drop_index(op.f('items_content_hash_idx'), table_name='items')
    op.drop_index(op.f('items_feed_timeline_idx'), table_name='items')
    op.drop_index(op.f('items_published_idx'), table_name='items')
    op.alter_column('sources', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('sources', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.create_index(op.f('items_published_idx'), 'items', [sa.literal_column('published DESC NULLS LAST')], unique=False)
    op.create_index(op.f('items_feed_timeline_idx'), 'items', ['feed_id', sa.literal_column('created_at DESC')], unique=False)
    op.create_index(op.f('items_content_hash_idx'), 'items', ['content_hash'], unique=True)
    op.add_column('item_analysis', sa.Column('impact_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False, comment='JSON containing impact score and volatility metrics'))
    op.add_column('item_analysis', sa.Column('sentiment_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False, comment='JSON containing overall sentiment, urgency, and themes'))
    op.create_table_comment(
        'item_analysis',
        'Stores LLM-generated sentiment and impact analysis for news items',
        existing_comment=None,
        schema=None
    )
    op.drop_constraint(None, 'item_analysis', type_='foreignkey')
    op.create_foreign_key(op.f('item_analysis_item_id_fkey'), 'item_analysis', 'items', ['item_id'], ['id'], ondelete='CASCADE')
    op.drop_constraint(None, 'item_analysis', type_='unique')
    op.drop_index(op.f('ix_item_analysis_urgency_score'), table_name='item_analysis')
    op.drop_index(op.f('ix_item_analysis_updated_at'), table_name='item_analysis')
    op.drop_index(op.f('ix_item_analysis_sentiment_label'), table_name='item_analysis')
    op.drop_index(op.f('ix_item_analysis_impact_overall'), table_name='item_analysis')
    op.create_index(op.f('item_analysis_item_id_idx'), 'item_analysis', ['item_id'], unique=False)
    op.create_index(op.f('idx_item_analysis_urgency'), 'item_analysis', [sa.literal_column("((sentiment_json ->> 'urgency'::text)::numeric)")], unique=False)
    op.create_index(op.f('idx_item_analysis_updated'), 'item_analysis', [sa.literal_column('updated_at DESC')], unique=False)
    op.create_index(op.f('idx_item_analysis_sentiment_label'), 'item_analysis', [sa.literal_column("((sentiment_json -> 'overall'::text) ->> 'label'::text)")], unique=False)
    op.create_index(op.f('idx_item_analysis_impact_overall'), 'item_analysis', [sa.literal_column("((impact_json ->> 'overall'::text)::numeric)")], unique=False)
    op.alter_column('item_analysis', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('item_analysis', 'model_tag',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               comment='LLM model identifier used for analysis',
               existing_nullable=True)
    op.alter_column('item_analysis', 'item_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False)
    op.drop_column('item_analysis', 'created_at')
    op.drop_column('item_analysis', 'raw_analysis_data')
    op.drop_column('item_analysis', 'impact_overall')
    op.drop_column('item_analysis', 'relevance_score')
    op.drop_column('item_analysis', 'urgency_score')
    op.drop_column('item_analysis', 'impact_score')
    op.drop_column('item_analysis', 'sentiment_label')
    op.drop_column('item_analysis', 'sentiment_score')
    op.drop_column('item_analysis', 'id')
    op.drop_column('feed_types', 'updated_at')
    op.alter_column('feed_health', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('dynamic_feed_templates', 'usage_count',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.add_column('analysis_runs', sa.Column('eta_seconds', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('coverage_10m', sa.NUMERIC(precision=5, scale=4), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('items_per_min', sa.NUMERIC(precision=8, scale=2), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('params_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('failed_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('last_error', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('coverage_60m', sa.NUMERIC(precision=5, scale=4), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('actual_cost', sa.NUMERIC(precision=10, scale=4), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('processed_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('scope_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('error_rate', sa.NUMERIC(precision=5, scale=4), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.add_column('analysis_runs', sa.Column('queued_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('analysis_runs', sa.Column('cost_estimate', sa.NUMERIC(precision=10, scale=4), server_default=sa.text('0.0'), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_analysis_runs_status'), table_name='analysis_runs')
    op.drop_index(op.f('ix_analysis_runs_scope_hash'), table_name='analysis_runs')
    op.drop_index(op.f('ix_analysis_runs_created_at'), table_name='analysis_runs')
    op.create_index(op.f('idx_analysis_runs_status'), 'analysis_runs', ['status'], unique=False)
    op.create_index(op.f('idx_analysis_runs_scope_hash'), 'analysis_runs', ['scope_hash'], unique=False)
    op.create_index(op.f('idx_analysis_runs_created'), 'analysis_runs', [sa.literal_column('created_at DESC')], unique=False)
    op.alter_column('analysis_runs', 'scope_hash',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               nullable=False)
    op.alter_column('analysis_runs', 'status',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::text"))
    op.alter_column('analysis_runs', 'completed_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('analysis_runs', 'started_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('analysis_runs', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('analysis_runs', 'id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True,
               existing_server_default=sa.text("nextval('analysis_runs_id_seq'::regclass)"))
    op.drop_column('analysis_runs', 'model_tag')
    op.drop_column('analysis_runs', 'avg_processing_time')
    op.drop_column('analysis_runs', 'error_message')
    op.drop_column('analysis_runs', 'failed_items')
    op.drop_column('analysis_runs', 'processed_items')
    op.drop_column('analysis_runs', 'total_items')
    op.drop_column('analysis_runs', 'filters')
    op.add_column('analysis_run_items', sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False))
    op.add_column('analysis_run_items', sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('analysis_run_items', sa.Column('tokens_used', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('analysis_run_items', sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('analysis_run_items', sa.Column('cost_usd', sa.NUMERIC(precision=8, scale=6), server_default=sa.text('NULL::numeric'), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'analysis_run_items', type_='foreignkey')
    op.drop_constraint(None, 'analysis_run_items', type_='foreignkey')
    op.create_foreign_key(op.f('analysis_run_items_item_id_fkey'), 'analysis_run_items', 'items', ['item_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(op.f('analysis_run_items_run_id_fkey'), 'analysis_run_items', 'analysis_runs', ['run_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_analysis_run_items_state'), table_name='analysis_run_items')
    op.drop_index(op.f('ix_analysis_run_items_run_id'), table_name='analysis_run_items')
    op.drop_index(op.f('ix_analysis_run_items_item_id'), table_name='analysis_run_items')
    op.create_index(op.f('idx_run_items_state'), 'analysis_run_items', ['state'], unique=False)
    op.create_index(op.f('idx_run_items_run_id'), 'analysis_run_items', ['run_id'], unique=False)
    op.create_index(op.f('idx_run_items_item_id'), 'analysis_run_items', ['item_id'], unique=False)
    op.create_unique_constraint(op.f('analysis_run_items_run_id_item_id_key'), 'analysis_run_items', ['run_id', 'item_id'], postgresql_nulls_not_distinct=False)
    op.alter_column('analysis_run_items', 'error_message',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('analysis_run_items', 'state',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False,
               existing_server_default=sa.text("'queued'::text"))
    op.alter_column('analysis_run_items', 'item_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False)
    op.alter_column('analysis_run_items', 'run_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False)
    op.alter_column('analysis_run_items', 'id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)
    op.drop_column('analysis_run_items', 'retry_count')
    op.drop_column('analysis_run_items', 'processing_completed_at')
    op.drop_column('analysis_run_items', 'processing_started_at')
    op.add_column('analysis_presets', sa.Column('params_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False))
    op.add_column('analysis_presets', sa.Column('scope_json', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False))
    op.alter_column('analysis_presets', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('analysis_presets', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('analysis_presets', 'description',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('analysis_presets', 'name',
               existing_type=sqlmodel.sql.sqltypes.AutoString(),
               type_=sa.TEXT(),
               existing_nullable=False)
    op.alter_column('analysis_presets', 'id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)
    op.drop_column('analysis_presets', 'is_default')
    op.drop_column('analysis_presets', 'rate_per_second')
    op.drop_column('analysis_presets', 'model_tag')
    op.drop_column('analysis_presets', 'filters')
    op.create_table('queued_runs',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('priority', postgresql.ENUM('HIGH', 'MEDIUM', 'LOW', name='runpriority'), autoincrement=False, nullable=False),
    sa.Column('status', postgresql.ENUM('QUEUED', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', name='runstatus'), autoincrement=False, nullable=False),
    sa.Column('scope_hash', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('triggered_by', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('scope_json', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('params_json', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('analysis_run_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('queue_position', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('queued_runs_pkey'))
    )
    op.create_index(op.f('ix_queued_runs_status'), 'queued_runs', ['status'], unique=False)
    op.create_index(op.f('ix_queued_runs_scope_hash'), 'queued_runs', ['scope_hash'], unique=False)
    op.create_index(op.f('ix_queued_runs_queue_position'), 'queued_runs', ['queue_position'], unique=False)
    # ### end Alembic commands ###
